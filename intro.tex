\section{はじめに}
はじめに
abc.svm,hpo,郡知能.
・背景
SVMとはこういうものである。

機械学習モデルにはあらかじめ決めておかなければいけない値であるハイパーパラメータが存在する。
そして，機械学習モデルの性能を最大限発揮するためには，適切なハイパーパラメータの選択が必要不可欠である\cite{essential}．
ハイパーパラメータにはこれがある。
SVMのパラメータはそれぞれこういう特徴がある。

一般にハイパーパラメータ調整は手動やグリッドサーチ、ランダムサーチで行われる．
手動でハイパーパラメータを調節することは直感と経験に頼る作業になる．
グリッドサーチ、ランダムサーチは探索効率が悪い。
ハイパーパラメータ調整(Hyper Parameter Optimization(HPO))の分野では、離散、連続、カテゴリなど様々なハイパーパラメータを扱い、
広い探索空間を効率的に探索することが求められる．
HPOでは目的関数を評価するために，モデルの学
習が必要となる．このため，HPOにおいては，
多くの場合，目的関数の評価が実行時間におけるボト
ルネックとなり，評価回数と実行時間のトレードオフになる[4]．
 効率的にハイパーパラメータ空間を探索する様々な手法が提案されている。
その手法の1つとして，自然界の生物の群れが高度な振る舞いをすることをコンピュータに適用した群知能がある．郡知能にはABC，PSO，ACOなどのアルゴリズムがある[abc][5][6]。.
これらのアルゴリズムをSVMのハイパーパラメータ最適化や特徴選択に適用した事例がある[][][]。

郡知能の中でもABCはパラメータが少なく比較的シンプルなアルゴリズムである。
これらの研究では，SVMのカーネル関数を固定して実験を行っている．
SVMには，様々なカーネル関数が適用でき、それぞれのカーネル関数はハイパーパラメータの数が異なる。
ゆえにカーネル関数もハイパーパラメータとして扱うことができる．
そこで、本研究ではCに加えて4つのカーネル関数(線形，RBF，シグモイド，多項式)とそのハイパーパラメータも最適化対象とし、ABCを用いてSVMのハイパーパラメータ最適化を行う。


